.
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5226fd",
   "metadata": {},
   "source": [
    "# Post-Imputation Data Processing\n",
    "Authors: Rafaella Ormond and Jose Jaime Martinez-Magana <br>\n",
    "***Description:***<br>\n",
    "This script processes imputed data from TOPMED server, converting VCF files to PLINK format and performing quality control filtering\n",
    "\n",
    "### ***Requirements:***\n",
    "### Download Plink\n",
    "We can download Plink version 1.9 and version 2.0 following the steps from their website.<br>\n",
    "For install plink2 [access here](https://www.cog-genomics.org/plink/2.0/)<br>\n",
    "For install plink1.9 [access here](https://www.cog-genomics.org/plink/1.9/) <br>\n",
    "\n",
    "### TOPMED Imputation Results\n",
    "This script assumes you have already completed imputation using TOPMED server [link here](https://imputation.biodatacatalyst.nhlbi.nih.gov/#!) and downloaded the results<br>\n",
    "You should have chromosome-specific VCF files (chr1.dose.vcf.gz, chr2.dose.vcf.gz, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534fda3b-fe5f-4d62-8af8-9a1d1d09c074",
   "metadata": {},
   "source": [
    "Set your analysis parameters and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16c18d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONFIGURATION SECTION - MODIFY ACCORDING TO YOUR ANALYSIS\n",
    "# Base directory containing imputed VCF files from TOPMED\n",
    "inputPath=\"/path/to/your/imputed_vcf_files\"\n",
    "\n",
    "# Output directory for individual chromosome PLINK files\n",
    "outputSplitPath=\"/path/to/output/split_chromosomes\"\n",
    "\n",
    "# Output directory for merged chromosome files\n",
    "outputMergedPath=\"/path/to/output/merged_chromosomes\"\n",
    "\n",
    "# Output directory for LD-pruned files\n",
    "outputPrunedPath=\"/path/to/output/ld_pruned\"\n",
    "\n",
    "# Your cohort/study name (used for output file naming)\n",
    "cohortName=\"YOUR_COHORT_NAME\"\n",
    "\n",
    "# Password for unzipping TOPMED results (if needed)\n",
    "topmedPassword=\"YOUR_TOPMED_PASSWORD\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff39bb79-cf7b-463d-b73a-75433f9b0c07",
   "metadata": {},
   "source": [
    "Create output directories and validate inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1999b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories if they don't exist\n",
    "mkdir -p ${outputSplitPath}\n",
    "mkdir -p ${outputMergedPath}\n",
    "mkdir -p ${outputPrunedPath}\n",
    "\n",
    "# Validate that required tools are available\n",
    "command -v plink2 >/dev/null 2>&1 || { echo \"ERROR: plink2 not found\" >&2; exit 1; }\n",
    "command -v unzip >/dev/null 2>&1 || { echo \"ERROR: unzip not found\" >&2; exit 1; }\n",
    "\n",
    "echo \"Setup completed. Output directories created.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574bc244",
   "metadata": {},
   "source": [
    "### Step 1: Download TOPMED Imputation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba804291-57a7-4ffb-b7a7-31ead7cde8d7",
   "metadata": {},
   "source": [
    "***Description:***<br>\n",
    "Template for downloading TOPMED results. Replace URLs with your actual download links from TOPMED server<br>\n",
    "**Note: You need to replace these example URLs with your actual TOPMED result URLs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acb1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to input directory\n",
    "cd ${inputPath}\n",
    "\n",
    "# Download quality control report (replace URL with your actual TOPMED link)\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_QC_REPORT_URL/qcreport.html\n",
    "\n",
    "# Download QC statistics (replace URLs with your actual TOPMED links)\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_URL/chunks-excluded.txt\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_URL/snps-excluded.txt\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_URL/typed-only.txt\n",
    "\n",
    "# Download chromosome files (replace URLs with your actual TOPMED links)\n",
    "# Example for chromosome 1:\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_URL/chr_1.zip\n",
    "\n",
    "# Download MD5 checksum file\n",
    "# wget https://imputation.biodatacatalyst.nhlbi.nih.gov/share/results/YOUR_URL/results.md5\n",
    "\n",
    "echo \"Download section completed. Please replace URLs with your actual TOPMED links.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d8c4a9-1f69-4ee3-9016-a52f560c367a",
   "metadata": {},
   "source": [
    "***Description:***<br>\n",
    "Unzip TOPMED imputation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c2d8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to input directory\n",
    "cd ${inputPath}\n",
    "\n",
    "# Unzip all chromosome files\n",
    "if [ ! -z \"${topmedPassword}\" ]; then\n",
    "    echo \"Unzipping files with password...\"\n",
    "    for chr_file in *.zip\n",
    "    do\n",
    "        if [ -f \"${chr_file}\" ]; then\n",
    "            echo \"Unzipping ${chr_file}...\"\n",
    "            unzip -P ${topmedPassword} -o ${chr_file}\n",
    "        fi\n",
    "    done\n",
    "else\n",
    "    echo \"No password provided. Attempting to unzip without password...\"\n",
    "    for chr_file in *.zip\n",
    "    do\n",
    "        if [ -f \"${chr_file}\" ]; then\n",
    "            echo \"Unzipping ${chr_file}...\"\n",
    "            unzip -o ${chr_file}\n",
    "        fi\n",
    "    done\n",
    "fi\n",
    "\n",
    "echo \"Unzipping completed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9380d5b8-87cc-4ad4-8c71-eba4549b2e92",
   "metadata": {},
   "source": [
    "***Description:***<br>\n",
    "Convert VCF files to PLINK format for each chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41e439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dose VCF files to PLINK format for each chromosome\n",
    "echo \"Converting VCF files to PLINK format...\"\n",
    "\n",
    "for chr in {1..22}\n",
    "do\n",
    "    echo \"Processing chromosome ${chr}...\"\n",
    "    \n",
    "    # Check if input file exists\n",
    "    if [ -f \"${inputPath}/chr${chr}.dose.vcf.gz\" ]; then\n",
    "        plink2 --vcf ${inputPath}/chr${chr}.dose.vcf.gz \\\n",
    "               --make-pgen \\\n",
    "               --id-delim '_' \\\n",
    "               --rm-dup 'force-first' \\\n",
    "               --snps-only \\\n",
    "               --out ${outputSplitPath}/${cohortName}_chr${chr}_dose\n",
    "        \n",
    "        echo \"Chromosome ${chr} conversion completed.\"\n",
    "    else\n",
    "        echo \"WARNING: File chr${chr}.dose.vcf.gz not found. Skipping...\"\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"All chromosome conversions completed.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0113731b-61f9-471f-aaf5-c8a135f864b8",
   "metadata": {},
   "source": [
    "***Description:***<br>\n",
    "Merge all chromosomes into a single dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b56b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to split files directory\n",
    "cd ${outputSplitPath}\n",
    "\n",
    "# Create list of PLINK files for merging (chromosomes 2-22)\n",
    "echo \"Creating file list for merging...\"\n",
    "for chr in {2..22}\n",
    "do\n",
    "    if [ -f \"${cohortName}_chr${chr}_dose.pgen\" ]; then\n",
    "        echo \"${cohortName}_chr${chr}_dose\" >> plink_merge_list.txt\n",
    "    fi\n",
    "done\n",
    "\n",
    "# Check if chromosome 1 file exists for base merge\n",
    "if [ -f \"${cohortName}_chr1_dose.pgen\" ]; then\n",
    "    echo \"Merging all chromosomes...\"\n",
    "    \n",
    "    # Merge all chromosomes using chromosome 1 as base\n",
    "    plink2 --pfile ${cohortName}_chr1_dose \\\n",
    "           --pmerge-list plink_merge_list.txt pfile \\\n",
    "           --multiallelics-already-joined \\\n",
    "           --out ${outputMergedPath}/${cohortName}_merged_all_chr\n",
    "    \n",
    "    echo \"Chromosome merging completed.\"\n",
    "    \n",
    "    # Set variant IDs to chr:bp:ref:alt format and filter for SNPs only\n",
    "    echo \"Setting variant IDs and filtering SNPs...\"\n",
    "    plink2 --pfile ${outputMergedPath}/${cohortName}_merged_all_chr \\\n",
    "           --set-all-var-ids '@:#:$r:$a' \\\n",
    "           --snps-only 'just-acgt' \\\n",
    "           --make-pgen \\\n",
    "           --out ${outputMergedPath}/${cohortName}_merged_snps_only\n",
    "    \n",
    "    echo \"Variant ID formatting completed.\"\n",
    "else\n",
    "    echo \"ERROR: Chromosome 1 file not found. Cannot proceed with merging.\"\n",
    "    exit 1\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4663b6",
   "metadata": {},
   "source": [
    "***Description:***<br>\n",
    "Perform LD pruning for population structure analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d98c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to output directory for LD pruning\n",
    "cd ${outputPrunedPath}\n",
    "\n",
    "echo \"Starting LD pruning process...\"\n",
    "\n",
    "# Perform LD pruning with quality control filters\n",
    "echo \"Step 1: Identifying variants for LD pruning...\"\n",
    "plink2 --pfile ${outputMergedPath}/${cohortName}_merged_snps_only \\\n",
    "       --rm-dup 'force-first' \\\n",
    "       --extract-if-info 'R2 > 0.4' \\\n",
    "       --snps-only 'just-acgt' \\\n",
    "       --maf 0.05 \\\n",
    "       --hwe 1e-10 \\\n",
    "       --geno 0.01 \\\n",
    "       --indep-pairwise 50 5 0.2 \\\n",
    "       --out ${cohortName}_ld_pruning_variants\n",
    "\n",
    "echo \"Step 2: Creating LD-pruned dataset...\"\n",
    "# Apply LD pruning filter to create final dataset\n",
    "plink2 --pfile ${outputMergedPath}/${cohortName}_merged_snps_only \\\n",
    "       --extract ${cohortName}_ld_pruning_variants.prune.in \\\n",
    "       --make-pgen \\\n",
    "       --out ${cohortName}_merged_ldpruned_final\n",
    "\n",
    "echo \"LD pruning completed successfully.\"\n",
    "\n",
    "# Generate summary statistics\n",
    "echo \"Generating summary statistics...\"\n",
    "plink2 --pfile ${cohortName}_merged_ldpruned_final --freq --missing --out ${cohortName}_final_stats\n",
    "\n",
    "echo \"Post-imputation processing pipeline completed.\"\n",
    "echo \"Final files are located in: ${outputPrunedPath}\"\n",
    "echo \"Main output file: ${cohortName}_merged_ldpruned_final.pgen/.psam/.pvar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "final_summary",
   "metadata": {},
   "source": [
    "### Summary of Processing Steps\n",
    "\n",
    "This script performs the following operations:\n",
    "1. **Downloads** TOPMED imputation results (URLs need to be customized)\n",
    "2. **Unzips** password-protected result files\n",
    "3. **Converts** chromosome-specific VCF files to PLINK format\n",
    "4. **Merges** all chromosomes into a single dataset\n",
    "5. **Standardizes** variant IDs to chr:bp:ref:alt format\n",
    "6. **Performs** LD pruning with quality control filters:\n",
    "   - Imputation quality R² > 0.4\n",
    "   - Minor allele frequency > 5%\n",
    "   - Hardy-Weinberg equilibrium p > 1e-10\n",
    "   - Genotyping rate > 99%\n",
    "   - LD pruning: window 50kb, step 5 variants, r² threshold 0.2\n",
    "\n",
    "### Quality Control Parameters Used:\n",
    "- **MAF filter**: 0.05 (removes rare variants)\n",
    "- **HWE filter**: 1e-10 (removes variants with extreme deviation from HWE)\n",
    "- **Genotyping rate**: 0.01 (removes variants with >1% missing data)\n",
    "- **Imputation quality**: R² > 0.4 (keeps well-imputed variants only)\n",
    "- **LD pruning**: r² < 0.2 (creates independent variant set)\n",
    "\n",
    "### Output Files:\n",
    "The final LD-pruned dataset will be ready for downstream analyses such as:\n",
    "- Population structure analysis (PCA)\n",
    "- Genome-wide association studies (GWAS)\n",
    "- Polygenic risk score calculations\n",
    "- Population genetics analyses"
   ]
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 5
}
